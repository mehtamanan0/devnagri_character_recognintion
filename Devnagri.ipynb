{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Approach\n",
    "\n",
    "For the current task, i've used a basic cnn classifier with 2 convolution layers with 32 and 64 filters.\n",
    "\n",
    "As this is a simple image classification task, A cnn would work the best for a 2d input rather than a simple ML classifier which takes a 1D feature.\n",
    "\n",
    "## The Data\n",
    "\n",
    "The data consists of about 78200 training samples in the form of images in each directory of the corresponding labels. \n",
    "\n",
    "I loaded the data into a numpy array from png images, i preprocessed them to have smaller values for faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import os\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all labels into a list for further processing\n",
    "dirlis = ['character_1_ka','character_2_kha','character_3_ga', 'character_4_gha','character_5_kna',\n",
    " 'character_6_cha','character_7_chha', 'character_8_ja', 'character_9_jha', 'character_10_yna','character_11_taamatar',\n",
    " 'character_12_thaa','character_13_daa', 'character_14_dhaa', 'character_15_adna', 'character_16_tabala','character_17_tha','character_18_da',\n",
    " 'character_19_dha','character_20_na','character_21_pa', 'character_22_pha', 'character_23_ba',\n",
    " 'character_24_bha', 'character_25_ma', 'character_26_yaw', 'character_27_ra', 'character_28_la',\n",
    " 'character_29_waw', 'character_30_motosaw', 'character_31_petchiryakha', 'character_32_patalosaw',\n",
    " 'character_33_ha', 'character_34_chhya', 'character_35_tra', 'character_36_gya',\n",
    " 'digit_0','digit_1', 'digit_2','digit_3', 'digit_4', 'digit_5', 'digit_6', 'digit_7', 'digit_8',\n",
    " 'digit_9']\n",
    "\n",
    "# initialising the x and y variables\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "# defining parameters for the cnn\n",
    "batch_size = 128\n",
    "num_classes = 46\n",
    "epochs = 12\n",
    "\n",
    "# size of the images\n",
    "img_rows, img_cols = 32, 32\n",
    "\n",
    "# iterate over each directory in the dataset and append into x_train and y_train\n",
    "i = 0\n",
    "for d in dirlis:\n",
    "    for each in os.listdir(\"{}/{}\".format(\"data/training_data/Train\", d)):\n",
    "        x_train.append(imageio.imread(\"{}/{}/{}\".format(\"data/training_data/Train\",d,each)))\n",
    "        y_train.append(i) \n",
    "    i += 1\n",
    "        \n",
    "# iterate over each directory in the dataset and append into x_test and y_test\n",
    "i = 0\n",
    "for d in dirlis:\n",
    "    for each in os.listdir(\"{}/{}\".format(\"data/training_data/Test\", d)):\n",
    "        x_test.append(imageio.imread(\"{}/{}/{}\".format(\"data/training_data/Test\",d,each)))\n",
    "        y_test.append(i) \n",
    "    i += 1\n",
    "\n",
    "# converting list of numpy arrays to numpy arrays\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# as the convolution layer takes channels last we resize it.\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# To nomalise the values so as to have a lighter model that trains faster.\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Converting labels to categorical classes in an array of 46 elements where the label respresent's 1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Used 2 conv2d layers with 32 and 64 filters with a size of 3 X 3\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# adding a maxpool layer with a size of 2 X 2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Dropping out 25% of the neurons randomly\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 78200 samples, validate on 13800 samples\n",
      "Epoch 1/12\n",
      "78200/78200 [==============================] - 375s 5ms/step - loss: 1.1914 - acc: 0.6643 - val_loss: 0.2467 - val_acc: 0.9347\n",
      "Epoch 2/12\n",
      "78200/78200 [==============================] - 371s 5ms/step - loss: 0.4234 - acc: 0.8736 - val_loss: 0.1541 - val_acc: 0.9528\n",
      "Epoch 3/12\n",
      "78200/78200 [==============================] - 371s 5ms/step - loss: 0.3036 - acc: 0.9078 - val_loss: 0.1249 - val_acc: 0.9639\n",
      "Epoch 4/12\n",
      "78200/78200 [==============================] - 364s 5ms/step - loss: 0.2453 - acc: 0.9245 - val_loss: 0.1026 - val_acc: 0.9701\n",
      "Epoch 5/12\n",
      "78200/78200 [==============================] - 362s 5ms/step - loss: 0.2036 - acc: 0.9367 - val_loss: 0.1046 - val_acc: 0.9687\n",
      "Epoch 6/12\n",
      "78200/78200 [==============================] - 366s 5ms/step - loss: 0.1773 - acc: 0.9460 - val_loss: 0.0938 - val_acc: 0.9732\n",
      "Epoch 7/12\n",
      "78200/78200 [==============================] - 368s 5ms/step - loss: 0.1612 - acc: 0.9492 - val_loss: 0.0838 - val_acc: 0.9761\n",
      "Epoch 8/12\n",
      "78200/78200 [==============================] - 372s 5ms/step - loss: 0.1416 - acc: 0.9560 - val_loss: 0.0826 - val_acc: 0.9767\n",
      "Epoch 9/12\n",
      "78200/78200 [==============================] - 369s 5ms/step - loss: 0.1298 - acc: 0.9588 - val_loss: 0.0816 - val_acc: 0.9759\n",
      "Epoch 10/12\n",
      "78200/78200 [==============================] - 363s 5ms/step - loss: 0.1212 - acc: 0.9621 - val_loss: 0.0746 - val_acc: 0.9791\n",
      "Epoch 11/12\n",
      "78200/78200 [==============================] - 363s 5ms/step - loss: 0.1136 - acc: 0.9632 - val_loss: 0.0737 - val_acc: 0.9786\n",
      "Epoch 12/12\n",
      "78200/78200 [==============================] - 374s 5ms/step - loss: 0.1071 - acc: 0.9664 - val_loss: 0.0728 - val_acc: 0.9796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62fdd48b70>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.07282351095235398\n",
      "Test accuracy: 0.9795652173913043\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"data/models/final.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
